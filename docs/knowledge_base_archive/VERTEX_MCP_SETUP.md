# âœ… VERTEX AI MCP - SETUP COMPLETO

**Status:** FUNCIONANDO  
**Fecha:** 2026-02-12  
**MCP Server:** `/mcp-vertex-simple/server.py`  

---

## ðŸš€ Inicio RÃ¡pido

### Usar el MCP Directamente

```bash
# Ver herramientas disponibles
mcporter list --config /home/claudio.alcaman/.openclaw/workspace/config/mcporter.json

# Hacer una llamada
mcporter call --config /home/claudio.alcaman/.openclaw/workspace/config/mcporter.json \
  vertex.generate \
  prompt="Â¿CuÃ¡l es la capital de Francia?" \
  --output json
```

### Desde Python (Directo)

```python
import sys
sys.path.insert(0, '/home/claudio.alcaman/.openclaw/workspace')

from vertex_models import generate

# Usar cualquier modelo Gemini
resultado = generate('vertex/gemini-3-pro-preview', 'Tu prompt aquÃ­')
print(resultado)
```

---

## ðŸ“Š ConfiguraciÃ³n

| ParÃ¡metro | Valor |
|-----------|-------|
| **Proyecto** | project-a65bf396-8524-45f7-8d6 |
| **MCP Server** | /mcp-vertex-simple/server.py |
| **MCP Config** | /config/mcporter.json |
| **SDK** | google-genai (Gemini) |
| **Modelos Disponibles** | gemini-3-pro-preview, gemini-2-5-flash |
| **Herramienta Expuesta** | `generate` |

---

## ðŸ”Œ Modelos Disponibles

```
âœ… vertex/gemini-3-pro-preview (Reasoning, anÃ¡lisis profundo)
âœ… vertex/gemini-2-5-flash (RÃ¡pido, multimodal)
âš ï¸  Claude modelos: Sin recursos en el proyecto
```

---

## ðŸ“ Ejemplo de Uso - MCP

```bash
# Test simple
mcporter call --config config/mcporter.json vertex.generate \
  prompt="Â¿QuÃ© es machine learning?" \
  --output json
```

**Respuesta esperada:**
```json
{
  "server": "vertex",
  "tool": "generate",
  "result": {
    "content": [
      {
        "type": "text",
        "text": "Machine learning es una rama de la IA..."
      }
    ]
  }
}
```

---

## ðŸ” Credenciales

- **UbicaciÃ³n:** `.vertex-key.json` (en workspace)
- **Formato:** Service Account JSON
- **Permisos:** Vertex AI User role âœ…
- **AutenticaciÃ³n:** GOOGLE_APPLICATION_CREDENTIALS

**âš ï¸ IMPORTANTE:** 
- No compartir `.vertex-key.json`
- Rotar claves regularmente
- DespuÃ©s de terminar, considerar revocar

---

## ðŸ› ï¸ Arquitectura

```
OpenClaw
    â†“
mcporter
    â†“
MCP Server (Python)
    â†“
vertex_models.generate()
    â†“
Google Genai SDK
    â†“
Vertex AI API (Gemini)
```

---

## âœ¨ Features

âœ… **MÃºltiples modelos** - Alterna entre gemini-3-pro-preview y gemini-2.5-flash  
âœ… **Caching de clientes** - Reutiliza conexiones  
âœ… **Error handling** - Manejo de cuota exhausted (429)  
âœ… **MCP compatible** - Funciona con cualquier cliente MCP  
âœ… **Production ready** - Credenciales seguras, logging, timeouts  

---

## ðŸ”§ Troubleshooting

### MCP offline
```bash
# Verificar que el servidor se inicia
python3 /mcp-vertex-simple/server.py &
# DeberÃ­a responder a stdin/stdout
```

### Modelo no encontrado (404)
```bash
# Verificar disponibilidad
mcporter call vertex.generate prompt="test" 2>&1 | grep -i "404\|not found"
# Si 404: Modelo no habilitado en proyecto
```

### Cuota exhausted (429)
```bash
# Esperar 5-30 minutos o usar otro modelo
mcporter call vertex.generate prompt="..." model="vertex/gemini-2-5-flash"
```

---

## ðŸ“š DocumentaciÃ³n Relacionada

- `VERTEX_AI_SUMMARY.md` - Resumen ejecutivo
- `VERTEX_AI_RULES.md` - Reglas formales
- `VERTEX_AI_USAGE.md` - GuÃ­a de uso
- `VERTEX_AI_REPLICATION_GUIDE.md` - CÃ³mo replicar

---

## âœ… Checklist

```
[âœ“] MCP Server creado y funcionando
[âœ“] mcporter configurado
[âœ“] Credenciales vÃ¡lidas
[âœ“] Gemini modelos accesibles
[âœ“] DocumentaciÃ³n completa
[âœ“] Error handling implementado
[âœ“] Ready para producciÃ³n
```

---

**MCP Vertex AI estÃ¡ listo para usar.** ðŸŽ¯

Para usar en OpenClaw o desde Python, consulta la secciÃ³n "Inicio RÃ¡pido" arriba.
