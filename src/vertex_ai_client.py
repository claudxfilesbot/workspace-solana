["str] = None):\n        \"", "\n        Inicializar cliente de Vertex AI\n        \n        Lee la configuraci\u00f3n de:\n        - GOOGLE_CLOUD_PROJECT (project_id)\n        - GOOGLE_CLOUD_LOCATION (region)\n        - VERTEX_AI_DEFAULT_MODEL (modelo por defecto)\n        - GCS_BUCKET (bucket de almacenamiento)\n        \"", "\n        self.project_id = project_id or os.getenv('GOOGLE_CLOUD_PROJECT')\n        self.region = os.getenv('GOOGLE_CLOUD_LOCATION', 'us-central1')\n        self.bucket = os.getenv('GCS_BUCKET', 'tu-bucket-nombre')\n        self.default_model = os.getenv('VERTEX_AI_DEFAULT_MODEL', 'gemini-2.5-pro')\n        \n        if not self.project_id:\n            raise ValueError(\"GOOGLE_CLOUD_PROJECT no est\u00e1 configurado en .env", "def get_config(self) -> Dict[str, Any]:\n        \"", "Retornar configuraci\u00f3n actual\"", "\n        return {\n            \"project_id", "self.project_id,\n            \"bucket", "self.bucket,\n            \"region", "self.region,\n            \"default_model", "self.default_model\n        }\n\n    def generate_script(self, prompt: str, model: Optional[str] = None) -> str:\n        \"", "\n        Generar guion usando Gemini 2.5 Pro\n        \n        Args:\n            prompt: El prompt completo con contexto del video\n            model: El modelo espec\u00edfico (usar default si no se especifica)\n        \n        Returns:\n            El guion generado como texto con formato [VISUAL] y [M\u00daSICA]\n        \"", "\n        model_name = model or self.default_model\n        \n        print(f\"\ud83c\udfac Generando guion con {model_name}\")\n        print(f\"   Project: {self.project_id}\")\n        print(f\"   Region: {self.region}\")\n        print(f", "Prompt preview: {prompt[:100]}...\")\n        \n        try:\n            from vertexai.generative_models import GenerativeModel\n            \n            generative_model = GenerativeModel(model_name)\n            response = generative_model.generate_content(prompt)\n            \n            script = response.text\n            print(f\"\n   \u2713 Guion generado ({len(script)} caracteres)\")\n            return script\n            \n        except ImportError:\n            print(f\"\n   \u26a0 SDK de Vertex AI no instalado\")\n            print(f\"      Ejecuta: pip install google-cloud-aiplatform\")\n            raise\n        except Exception as e:\n            print(f\"\n   \u2717 Error generando guion: {e}", "raise\n\n    def generate_image(self, prompt: str, model: Optional[str] = None) -> str:\n        \"", "\n        Generar imagen usando Imagen 4/4 Ultra\n        \n        Args:\n            prompt: La descripci\u00f3n de la imagen\n            model: imagen-4, imagen-4-ultra, o imagen-4-fast\n        \n        Returns:\n            Ruta al archivo de imagen generada\n        \"", "\n        image_model_name = model or \"imagen-4\"\n        \n        print(f\"\ud83d\uddbc\ufe0f  Generando imagen con {image_model_name}\")\n        print(f", "Prompt preview: {prompt[:100]}...\")\n        \n        output_dir = \"../output/assets", "os.makedirs(output_dir, exist_ok=True)\n        \n        try:\n            # Versi\u00f3n local con Vertex AI SDK\n            from vertexai.generative_models import ImageGenerationModel\n            \n            image_model = ImageGenerationModel(image_model_name)\n            images = image_model.generate_images(\n                prompt=prompt,\n                number_of_images=1,\n                aspect_ratio=\"1:1", "safety_filter_level=\"medium\"\n            )\n            \n            image_path = f\"{output_dir}/{self.project_id}-image-{int(time.time())}.png", "images[0].save_multipart_request(image_path)\n            \n            print(f\"   \u2713 Imagen guardada: {image_path}\")\n            return image_path\n            \n        except ImportError:\n            print(f\"   \u26a0 SDK de Vertex AI no instalado\")\n            print(f\"      Ejecuta: pip install google-cloud-aiplatform\")\n            raise\n        except Exception as e:\n            print(f\"   \u2717 Error generando imagen: {e}\")\n            # Fallback: crear placeholder\n            image_path = f\"{output_dir}/{self.project_id}-image-{int(time.time())}-placeholder.png", "with open(image_path, 'w') as f:\n                f.write(f\"TODO: {str(e)}\")\n            print(f\"   \u26a0 Usando placeholder: {image_path}", "return image_path\n\n    def generate_video(self, prompt: str, model: Optional[str] = None) -> str:\n        \"", "\n        Generar video usando Veo 3.1\n        \n        Args:\n            prompt: La descripci\u00f3n completa del video con contexto\n            model: veo-3.1, veo-3.1-fast, o veo-2\n        \n        Returns:\n            Ruta al archivo de video generada\n        \"", "\n        video_model_name = model or \"veo-3.1\"\n        \n        print(f\"\ud83c\udfa5 Generando video con {video_model_name}\")\n        print(f\"   Prompt length: {len(prompt)} chars\")\n        print(f\"   Region: {self.region}\")\n        \n        output_dir = \"../output/clips", "os.makedirs(output_dir, exist_ok=True)\n        \n        try:\n            import vertexai.generative_models as genai\n            \n            video_model = genai.VideoGenerationModel(video_model_name)\n            video = video_model.generate_content(prompt)\n            \n            video_path = f\"{output_dir}/{self.project_id}-video-{int(time.time())}.mp4\"\n            video.save_multipart_request(video_path)\n            \n            print(f\"   \u2713 Video guardado: {video_path}\")\n            return video_path\n            \n        except ImportError:\n            print(f\"   \u26a0 SDK de Vertex AI no instalado\")\n            print(f\"      Ejecuta: pip install google-cloud-aiplatform\")\n            raise\n        except Exception as e:\n            print(f\"   \u2717 Error generando video: {e}\")\n            # Fallback: crear placeholder\n            video_path = f\"{output_dir}/{self.project_id}-video-{int(time.time())}-placeholder.mp4", "with open(video_path, 'w') as f:\n                f.write(f\"TODO: {str(e)}\")\n            print(f\"   \u26a0 Usando placeholder: {video_path}", "return video_path\n\n    def generate_voice(self, script: str, voice: Optional[str] = None) -> str:\n        \"", "\n        Generar narraci\u00f3n con Chirp 3\n        \n        Args:\n            script: El guion completo para convertir a voz\n            voice: El speaker a usar (ej: 'es-ES-NatashaNeural', 'en-US-GuyNeural')\n        \n        Returns:\n            Ruta al archivo de audio generado\n        \"", "\n        voice_name = voice or \"es-ES-NatashaNeural\"\n        \n        print(f\"\ud83c\udf99\ufe0f  Generando narraci\u00f3n con Chirp 3\")\n        print(f\"   Voice: {voice_name}\")\n        print(f\"   Script length: {len(script)} chars\")\n        \n        output_dir = \"../output/audio", "os.makedirs(output_dir, exist_ok=True)\n        \n        try:\n            # Versi\u00f3n con Google Cloud Text-to-Speech (Chirp 3)\n            from google.cloud import texttospeech\n            \n            client = texttospeech.TextToSpeechClient(credentials=None)\n            \n            input_text = texttospeech.SynthesisInput(text=script)\n            \n            # Configuraci\u00f3n de voz Chirp 3\n            voice = texttospeech.VoiceSelectionParams(\n                language_code=voice_name.split('-')[0],  # es, en, etc.\n                name=voice_name,\n                ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n            )\n            \n            audio_config = texttospeech.AudioConfig(\n                audio_encoding=texttospeech.AudioEncoding.LINEAR16,\n                speaking_rate=1.0,\n                pitch=0.0\n            )\n            \n            response = client.synthesize_speech(\n                input=input_text,\n                voice=voice,\n                audio_config=audio_config\n            )\n            \n            audio_path = f\"{output_dir}/{self.project_id}-narration-{int(time.time())}.wav", "with open(audio_path, 'wb') as f:\n                f.write(response.audio_content)\n            \n            print(f\"   \u2713 Narraci\u00f3n guardada: {audio_path}\")\n            return audio_path\n            \n        except ImportError:\n            print(f\"   \u26a0 SDK de Google Cloud TTS no instalado\")\n            print(f\"      Ejecuta: pip install google-cloud-texttospeech\")\n            raise\n        except Exception as e:\n            print(f\"   \u2717 Error generando narraci\u00f3n: {e}\")\n            # Fallback: crear placeholder\n            audio_path = f\"{output_dir}/{self.project_id}-narration-{int(time.time())}-placeholder.wav", "with open(audio_path, 'w') as f:\n                f.write(f\"TODO: {str(e)}\")\n            print(f\"   \u26a0 Usando placeholder: {audio_path}", "return audio_path\n\n    def generate_music(self, prompt: str, model: Optional[str] = None) -> str:\n        \"", "\n        Generar m\u00fasica con Lyria 2\n        \n        Args:\n            prompt: La descripci\u00f3n del estilo, tono y caracter\u00edsticas de la m\u00fasica\n            model: lyria-2 (Lyria 2.0)\n        \n        Returns:\n            Ruta al archivo de m\u00fasica generada\n        \"", "\n        music_model_name = model or \"lyria-2\"\n        \n        print(f\"\ud83c\udfb5 Generando m\u00fasica con {music_model_name}\")\n        print(f", "Music prompt: {prompt[:100]}...\")\n        \n        output_dir = \"../output/music", "os.makedirs(output_dir, exist_ok=True)\n        \n        try:\n            # Versi\u00f3n con Google Cloud Text-to-Speech (Lyria 2)\n            from google.cloud import texttospeech\n            \n            client = texttospeech.TextToSpeechClient(credentials=None)\n            \n            input_text = texttospeech.SynthesisInput(text=prompt)\n            \n            # Configuraci\u00f3n de voz Lyria 2 para m\u00fasica\n            voice = texttospeech.VoiceSelectionParams(\n                language_code=\"es-ES", "name=music_model_name,\n                ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n            )\n            \n            audio_config = texttospeech.AudioConfig(\n                audio_encoding=texttospeech.AudioEncoding.MP3,\n                speaking_rate=1.0,\n                pitch=0.0\n            )\n            \n            response = client.synthesize_speech(\n                input=input_text,\n                voice=voice,\n                audio_config=audio_config\n            )\n            \n            music_path = f\"{output_dir}/{self.project_id}-music-{int(time.time())}.mp3", "with open(music_path, 'wb') as f:\n                f.write(response.audio_content)\n            \n            print(f\"   \u2713 M\u00fasica guardada: {music_path}\")\n            return music_path\n            \n        except ImportError:\n            print(f\"   \u26a0 SDK de Google Cloud TTS no instalado\")\n            print(f\"      Ejecuta: pip install google-cloud-texttospeech\")\n            raise\n        except Exception as e:\n            print(f\"   \u2717 Error generando m\u00fasica: {e}\")\n            # Fallback: crear placeholder\n            music_path = f\"{output_dir}/{self.project_id}-music-{int(time.time())}-placeholder.mp3", "with open(music_path, 'w') as f:\n                f.write(f\"TODO: {str(e)}\")\n            print(f\"   \u26a0 Usando placeholder: {music_path}\")\n            return music_path\n\n\nif __name__ == \"__main__\":\n    # Test b\u00e1sico\n    print(\"=\" * 70)\n    print(\"TEST DE INTEGRACI\u00d3N CON GOOGLE CLOUD - PRODUCCI\u00d3N MULTIMEDIA\")\n    print(\"=\" * 70)\n    print()\n    \n    # 1. Cargando configuraci\u00f3n\n    print(\"1\ufe0f\u20e3  Cargando configuraci\u00f3n...\")\n    client = VertexAIClient()\n    \n    config = client.get_config()\n    print(\"\u2713 Configuraci\u00f3n cargada:\")\n    print(f", "Project ID: {config['project_id']}\")\n    print(f", "Location: {config['region']}\")\n    print(f", "Default Model: {config['default_model']}\")\n    print(f", "Bucket: {config['bucket']}\")\n    print()\n    \n    # 2. Test de generaci\u00f3n de guion\n    print(\"2\ufe0f\u20e3  Test de generaci\u00f3n de guion...\")\n    test_prompt = (\n        \"Genera un guion de 60 segundos sobre 'La inteligencia artificial en el contenido multimedia'\n\"\n        \"con las siguientes secciones:\n\"\n        \"1. Hook en los primeros 3 segundos\n\"\n        \"2. Intro de 30 segundos\n\"\n        \"3. Conclusion de 30 segundos\n\n\"", "Incluye [VISUAL: descripcion detallada] y [MUSICA: tono/estilo] en cada secci\u00f3n.\n\"", "Formato: 16:9, estilo educativo y profesional\"\n    )\n    \n    try:\n        script = client.generate_script(test_prompt)\n        print(f\"\n\u2713 Guion generado exitosamente ({len(script)} caracteres)\")\n        print(f", "nPreview del guion:\n{script[:500]}...\")\n        \n        # Guardar guion\n        output_dir = \"../output/drafts", "os.makedirs(output_dir, exist_ok=True)\n        script_path = f\"{output_dir}/test-script-{int(time.time())}.md", "with open(script_path, 'w', encoding='utf-8') as f:\n            f.write(script)\n        print(f\"\n\u2713 Guion guardado: {script_path}\")\n        \n    except Exception as e:\n        print(f\"\n\u2717 Error en test de guion: {e}\")\n        import traceback\n        traceback.print_exc()\n    \n    print()\n    print(\"=\" * 70)\n    print(\"\u2705 TEST COMPLETADO\")\n    print(\"=\" * 70)\n    print()\n    print(\"NEXT STEPS:\")\n    print(\"  - Test de generaci\u00f3n de imagen\")\n    print(\"  - Test de generaci\u00f3n de video\")\n    print(\"  - Test de generaci\u00f3n de voz (Chirp 3)\")\n    print(\"  - Test de generaci\u00f3n de m\u00fasica (Lyria 2)\")\n    print(\"  - Ensamblado final con FFmpeg"]